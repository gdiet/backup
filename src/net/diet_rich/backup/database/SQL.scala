// Copyright (c) 2011 Georg Dietrich
// Licensed under the MIT license: http://www.opensource.org/licenses/mit-license.php
package net.diet_rich.backup.database
import net.diet_rich.util.io.SectionDataFile

object SQL {

  lazy val sectionsWithComments = SectionDataFile.getSections(sql.split("[\r\n]+").toIterator)
  lazy val sections = sectionsWithComments.mapValues(SectionDataFile.removeComments(_))
  lazy val sectionsWithConstraints = {
    val constraintKeys = sections.keys.filter(_.endsWith(" constraints"))
    val constraintMap = constraintKeys.map( key => (key, sections(key).mkString("\n")) ).toMap
    val noConstraintsMap = sections.filterKeys(!_.endsWith(" constraints"))
    noConstraintsMap.mapValues(SectionDataFile.insertVariables(_, constraintMap))
  }
  
  private val sql =
    """
[create tables]
CREATE TABLE Directories (
    pk     BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY NOT NULL,
    parent BIGINT NOT NULL,            // for root ONLY: self reference
    name   VARCHAR(256) NOT NULL
${Directories constraints}
);

[Directories constraints]
  , FOREIGN KEY (parent) REFERENCES Directories(pk)

[create tables]
CREATE TABLE StoredData (
    pk     BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY NOT NULL,
    size   BIGINT NOT NULL,            // entry size (uncompressed)
    usage  INTEGER DEFAULT 0 NOT NULL, // usage count
    method VARCHAR(10) NOT NULL        // store method (e.g. PLAIN, DEFLATE)
${StoredData constraints}
);

[StoredData constraints]
  , CHECK (size >= 0)

[create tables]
CREATE TABLE Files (
    pk     BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY NOT NULL,
    parent BIGINT NOT NULL,
    name   VARCHAR(256) NOT NULL,
    time   BIGINT NOT NULL,
    data   BIGINT NOT NULL
${Files constraints}
);

[Files constraints]
  , FOREIGN KEY (parent) REFERENCES Directories(pk)
  , FOREIGN KEY (data) REFERENCES StoredData(pk)

[create tables]
CREATE TABLE ByteStore (
    dataid BIGINT NULL,           // reference to StoredData#pk or NULL if free
    index  INTEGER NOT NULL,      // data part index
    start  BIGINT NOT NULL,       // data part start position
    fin    BIGINT NOT NULL        // data part end position + 1
${ByteStore constraints}
);

[ByteStore constraints]
  , UNIQUE (start)
  , UNIQUE (fin)
  , FOREIGN KEY (dataid) REFERENCES StoredData(pk)
  , CHECK (fin > start)


[END OF FILE]
    """
  
}


/*
[create tables]
CREATE TABLE dataentries (
    pk     BIGINT IDENTITY,       // entry key
    size   BIGINT,                // entry size
    header BIGINT,                // header checksum
    hash   BINARY(${hashlength})  // entry hash
    ${dataentries constraints}    // , UNIQUE (size, header, hash)
);

[dataentries constraints]
, UNIQUE (size, header, hash)

[create tables]
CREATE INDEX dataentries_size   ON dataentries (size);
CREATE INDEX dataentries_header ON dataentries (header);
CREATE INDEX dataentries_hash   ON dataentries (hash);

CREATE TABLE datachunks (
    key BIGINT,               // entry key
    part INTEGER,             // serial number of entry part
    size BIGINT,              // entry part size
    fileid BIGINT,            // data file ID
    location INTEGER,         // location in data file
    deleted BOOLEAN           // deleted flag
    ${datachunks constraints} // , FOREIGN KEY (key) REFERENCES dataentries(pk)
);

[datachunks constraints]
, FOREIGN KEY (key) REFERENCES dataentries(pk)

[create tables]
CREATE INDEX datachunks_key     ON datachunks (key);
CREATE INDEX datachunks_fileid  ON datachunks (fileid);
CREATE INDEX datachunks_deleted ON datachunks (deleted);
*/